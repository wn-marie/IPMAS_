# ğŸš€ START HERE - Quick Guide

## âœ… Simplest Way (Recommended)

**Just run this one command:**

```bash
python datasets/scripts/ml_pipeline.py
```

That's it! This will:
- âœ… Load all your datasets
- âœ… Create features automatically
- âœ… Train models with 80/20 split
- âœ… Generate visualizations
- âœ… Save the best model

**Time**: ~10-20 minutes depending on data size

---

## ğŸ“‹ Step-by-Step (If You Want More Control)

### **1ï¸âƒ£ First: Clean Your Data (Optional but Recommended)**

```bash
python datasets/scripts/preprocessing.py
```

This cleans your raw datasets and saves them to `datasets/processed/`

**Time**: 2-5 minutes

---

### **2ï¸âƒ£ Then: Train Models**

```bash
python datasets/scripts/ml_pipeline.py
```

**If you ran preprocessing**, edit `ml_pipeline.py` line 736:
```python
# Change this:
results, splits = pipeline.run_full_pipeline(use_preprocessed=False)

# To this:
results, splits = pipeline.run_full_pipeline(use_preprocessed=True)
```

This trains all models and saves the best one.

**Time**: 5-15 minutes

---

### **3ï¸âƒ£ Visualizations: DON'T RUN MANUALLY**

Visualizations are **automatically generated** by `ml_pipeline.py` - no need to run `visualizations.py` separately!

Check `datasets/processed/visualizations/` after training completes.

---

## ğŸ¯ Summary

**For beginners**: Run `ml_pipeline.py` only  
**For better results**: Run `preprocessing.py` first, then `ml_pipeline.py` with `use_preprocessed=True`  
**Visualizations**: Auto-generated, don't run separately

---

## ğŸ“‚ Check Your Results

After running, check:
- Models: `datasets/processed/models/`
- Visualizations: `datasets/processed/visualizations/`
- Features: `datasets/processed/ml_features.csv`

---

## â“ Having Issues?

See `TROUBLESHOOTING.md` for common problems and solutions.
